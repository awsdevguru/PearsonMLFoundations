{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMo+hv2SX6m/5ElHWf7Cafw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awsdevguru/PearsonMLFoundations/blob/dev/3_6_03_Hands_on_Lab_Adversarial_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adversarial Detection\n",
        "\n",
        "0) Objective\n",
        "\n",
        "* Create, analyze, and detect adversarial inputs against image classifiers.\n",
        "* Experience both attack (FGSM) and defense perspectives.\n",
        "* Learn simple but practical ML security concepts: vulnerability, detection, robustness.\n",
        "\n",
        "## 1) Setup\n",
        "* Load CIFAR-10 dataset (airplanes, cars, birds, etc.)."
      ],
      "metadata": {
        "id": "hp7b5ZmHceHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w70PmQUcX-p"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow matplotlib numpy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Load a pretrained model (e.g., tf.keras.applications.MobileNetV2 or a small CNN trained on CIFAR-10)."
      ],
      "metadata": {
        "id": "JTVSyQ1Wc5Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_test = y_test.flatten()"
      ],
      "metadata": {
        "id": "5tgF2NJ5cryJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Part 1: Generate Adversarial Examples\n",
        "\n",
        "### a) Define the FGSM attack\n",
        "\n"
      ],
      "metadata": {
        "id": "PjJlYkihcuWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "def fgsm_attack(image, label, model, eps=0.02):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        prediction = model(image)\n",
        "        loss = loss_object(label, prediction)\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    adv_image = image + eps * signed_grad\n",
        "    return tf.clip_by_value(adv_image, 0, 1)"
      ],
      "metadata": {
        "id": "qCENhDOecvSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Apply FGSM"
      ],
      "metadata": {
        "id": "96002ceTdBCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model for a few epochs (optional, but good for demonstration)\n",
        "# For a more robust demonstration, you might want to train it on x_train/y_train\n",
        "# This model is just a placeholder to resolve the NameError\n",
        "# For the purpose of this exercise, we will not train it heavily.\n",
        "print(\"Model created and compiled.\")"
      ],
      "metadata": {
        "id": "XufO77c4eexm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "image = tf.convert_to_tensor(x_test[idx:idx+1])\n",
        "label = tf.convert_to_tensor(y_test[idx:idx+1])\n",
        "adv = fgsm_attack(image, label, model)\n"
      ],
      "metadata": {
        "id": "9OqWMG0IdAdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Visualize and compare"
      ],
      "metadata": {
        "id": "ykeQ0DC0dF_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1,2,1); plt.imshow(image[0]); plt.title(\"Original\")\n",
        "plt.subplot(1,2,2); plt.imshow(adv[0]); plt.title(\"Adversarial\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5t8UyG88dEeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Part 2: Understand the Attack\n",
        "\n",
        "### a) Measure Perturbation"
      ],
      "metadata": {
        "id": "rgZQqIFJdYQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l2 = np.linalg.norm((adv - image).numpy())\n",
        "print(\"L2 perturbation:\", l2)"
      ],
      "metadata": {
        "id": "vyXamraedIco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Evaluate model prediction & confidence"
      ],
      "metadata": {
        "id": "5k0G2n_udc98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_orig = model.predict(image)\n",
        "pred_adv = model.predict(adv)\n",
        "print(\"Original:\", np.argmax(pred_orig), \"Adversarial:\", np.argmax(pred_adv))"
      ],
      "metadata": {
        "id": "zWmbOnyddb3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Part 3: Detection Strategies\n",
        "\n",
        "### a) Statistical detection (pixel distribution)"
      ],
      "metadata": {
        "id": "BfsfZ57hdgbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_std(img): return np.std(img)\n",
        "print(\"Std original:\", pixel_std(image), \"Std adversarial:\", pixel_std(adv))\n"
      ],
      "metadata": {
        "id": "4WCklCu6dipW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Input preprocessing\n",
        "\n",
        "Apply JPEG compression or Gaussian blur and re-evaluate prediction:"
      ],
      "metadata": {
        "id": "3IzH4gMLdlcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "blurred = cv2.GaussianBlur(adv[0].numpy(), (3,3), 0)\n",
        "plt.imshow(blurred)\n"
      ],
      "metadata": {
        "id": "RB9wQneTdjhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Confidence-based detection\n",
        "\n",
        "If model confidence drops sharply -> flag as suspicious."
      ],
      "metadata": {
        "id": "i3_aeOmPdozw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_diff = np.max(pred_orig) - np.max(pred_adv)\n",
        "print(\"Confidence drop:\", conf_diff)\n"
      ],
      "metadata": {
        "id": "UMQt5RModsi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Part 4: Defense Implementation\n",
        "\n",
        "### a) Simple defensive preprocessor"
      ],
      "metadata": {
        "id": "SEis2evpduKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def defend_input(x_3d):\n",
        "    # x_3d is expected to be a 3D tensor (H, W, C)\n",
        "    return tf.image.random_jpeg_quality(x_3d, 70, 100)"
      ],
      "metadata": {
        "id": "_zrUOIVbdw1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Adversarial training demonstration\n",
        "\n",
        "Retrain the model briefly using a mix of clean + FGSM samples.\n",
        "Evaluate improvement in robustness.\n",
        "\n",
        "## 6) Evaluation\n",
        "\n",
        "Compare model accuracy on clean vs. adversarial vs. defended inputs.\n",
        "\n",
        "Visualize:"
      ],
      "metadata": {
        "id": "j_GPEPmCdzTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's ensure the model is trained, as evaluating an untrained model will yield very low accuracy.\n",
        "# For demonstration purposes, we'll use placeholder values or run a quick training.\n",
        "\n",
        "# Placeholder for now, you would typically train the model on x_train, y_train here.\n",
        "if not model.built or not model.optimizer:\n",
        "    print(\"Model needs to be compiled and possibly trained first.\")\n",
        "    # Simplified training for demonstration if the model hasn't been trained\n",
        "    model.fit(x_train[:1000], y_train[:1000], epochs=1, verbose=0) # Train on a small subset for a quick run\n",
        "\n",
        "# Evaluate on clean test data\n",
        "_, acc_clean = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# To get acc_adv and acc_defended, we would need to generate a full adversarial test set and then evaluate it.\n",
        "# For now, let's use illustrative values or generate a small set.\n",
        "\n",
        "# Generate adversarial examples for a subset of the test set for evaluation\n",
        "adv_images = []\n",
        "adv_labels = []\n",
        "for i in range(len(x_test[:100])): # Process a small subset for speed\n",
        "    image_tensor = tf.convert_to_tensor(x_test[i:i+1])\n",
        "    label_tensor = tf.convert_to_tensor(y_test[i:i+1])\n",
        "    adv_img = fgsm_attack(image_tensor, label_tensor, model, eps=0.02)\n",
        "    adv_images.append(adv_img[0].numpy())\n",
        "    adv_labels.append(y_test[i])\n",
        "\n",
        "adv_images = np.array(adv_images)\n",
        "adv_labels = np.array(adv_labels)\n",
        "\n",
        "_, acc_adv = model.evaluate(adv_images, adv_labels, verbose=0)\n",
        "\n",
        "# Evaluate on defended adversarial examples\n",
        "# Pass each 3D image to defend_input and then stack them\n",
        "defended_adv_images = tf.stack([defend_input(tf.convert_to_tensor(img)) for img in adv_images])\n",
        "_, acc_defended = model.evaluate(defended_adv_images, adv_labels, verbose=0)\n",
        "\n",
        "labels = ['Clean', 'Adversarial', 'Defended']\n",
        "accs = [acc_clean, acc_adv, acc_defended]\n",
        "plt.bar(labels, accs)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy on Different Inputs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MOwhWoa5d2tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Discussion / Wrap-Up\n",
        "\n",
        "**Key takeaways:**\n",
        "\n",
        "* Even small perturbations can fool high-accuracy models.\n",
        "* Detection is difficult; adversarial examples mimic normal inputs.\n",
        "* Combining preprocessing, ensembles, and adversarial training improves resilience.\n",
        "* Continuous monitoring and retraining are essential in production."
      ],
      "metadata": {
        "id": "4YEPeAydd4s6"
      }
    }
  ]
}