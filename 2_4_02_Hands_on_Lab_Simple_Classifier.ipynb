{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+6RvQ148qi6qTolpN/9p1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awsdevguru/PearsonMLFoundations/blob/dev/2_4_02_Hands_on_Lab_Simple_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-On Lab: Simple Classifier (Titanic) — with Code\n",
        "\n",
        "**Goal:** build a reproducible pipeline that predicts Survived using scikit-learn.\n",
        "\n",
        "## 0) Setup & Data Load"
      ],
      "metadata": {
        "id": "C1wHqRX21Xsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab/Notebook setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Viz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data & model utils\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score, RocCurveDisplay\n",
        ")\n",
        "\n",
        "# Load Titanic from seaborn (reliable in Colab) or fallback to URL\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    df = sns.load_dataset(\"titanic\")\n",
        "except Exception:\n",
        "    df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UEF7DMdU1cEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#category counts\n",
        "df.count()"
      ],
      "metadata": {
        "id": "wxl-Yw3S1kAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Target & Feature Selection"
      ],
      "metadata": {
        "id": "-1VN5w791xt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Harmonize column names across sources\n",
        "df.columns = [c.strip().lower() for c in df.columns]\n",
        "\n",
        "# Pick a compact, informative feature set\n",
        "# Works for both seaborn and Kaggle-like versions\n",
        "candidate_cols = [c for c in df.columns if c in\n",
        "                  [\"survived\",\"pclass\",\"sex\",\"age\",\"sibsp\",\"parch\",\"fare\",\"embarked\"]]\n",
        "\n",
        "data = df[candidate_cols].copy()\n",
        "\n",
        "# Drop rows with missing target\n",
        "data = data.dropna(subset=[\"survived\"])\n",
        "\n",
        "X = data.drop(columns=[\"survived\"])\n",
        "y = data[\"survived\"].astype(int)\n",
        "\n",
        "X.head(), y.head()"
      ],
      "metadata": {
        "id": "pVZjRN441pZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Train/Test Split (stratify to keep class balance)"
      ],
      "metadata": {
        "id": "F6-QdftI2Rmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=73\n",
        ")\n",
        "\n",
        "y_train.value_counts(normalize=True), y_test.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "j6shsVkv11T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Preprocessing: Numeric vs Categorical"
      ],
      "metadata": {
        "id": "KFctCK2i2ecT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify column types present\n",
        "num_features = [c for c in [\"age\",\"sibsp\",\"parch\",\"fare\"] if c in X.columns]\n",
        "cat_features = [c for c in [\"pclass\",\"sex\",\"embarked\"] if c in X.columns]\n",
        "\n",
        "numeric_pipe = Pipeline(steps=[\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scale\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipe = Pipeline(steps=[\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipe, num_features),\n",
        "        (\"cat\", categorical_pipe, cat_features)\n",
        "    ]\n",
        ")\n",
        "preprocess"
      ],
      "metadata": {
        "id": "Qcfr5RVW2UMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Model: Logistic Regression in a Pipeline"
      ],
      "metadata": {
        "id": "lHkhZBui2nB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"model\", LogisticRegression(max_iter=1000, C=1.0))\n",
        "])\n",
        "\n",
        "clf"
      ],
      "metadata": {
        "id": "InEciVWO2gzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Train"
      ],
      "metadata": {
        "id": "CzdaJ2dh2uZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2dV6zd3w2pcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Evaluate (Accuracy, Precision, Recall, F1)"
      ],
      "metadata": {
        "id": "ehIcx7QJ20sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "print(\"F1       :\", f1_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "4a9Brn4H2wwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Confusion Matrix"
      ],
      "metadata": {
        "id": "CzCLNqf025X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Died (0)\",\"Survived (1)\"])\n",
        "disp.plot(values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix — Logistic Regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ben1VenI23Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) ROC-AUC & Probability Thresholds"
      ],
      "metadata": {
        "id": "cPjPHk8d28_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probabilities\n",
        "y_proba = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# ROC-AUC\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
        "plt.title(\"ROC Curve — Logistic Regression\")\n",
        "plt.show()\n",
        "\n",
        "# Try a custom threshold (e.g., 0.4)\n",
        "thr = 0.40\n",
        "y_pred_custom = (y_proba >= thr).astype(int)\n",
        "print(f\"Threshold={thr:.2f}  Acc={accuracy_score(y_test,y_pred_custom):.3f}  \"\n",
        "      f\"Prec={precision_score(y_test,y_pred_custom):.3f}  Rec={recall_score(y_test,y_pred_custom):.3f}  \"\n",
        "      f\"F1={f1_score(y_test,y_pred_custom):.3f}\")"
      ],
      "metadata": {
        "id": "9ncI2CsO269t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) Quick Cross-Validation on Train Set"
      ],
      "metadata": {
        "id": "jTvSVdVn3CUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"f1\")\n",
        "print(\"CV F1 mean ± std:\", f\"{cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "a7DPUais2_XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10) Inspect “Feature Effects” (approximate)\n",
        "\n",
        "For pipelines with one-hot, coefficients map to transformed columns. We'll recover feature names to pair with weights."
      ],
      "metadata": {
        "id": "2-NDFj8O3FO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refit on full training to ensure fitted steps\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get transformed feature names\n",
        "ohe = clf.named_steps[\"prep\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "cat_out = ohe.get_feature_names_out(cat_features) if len(cat_features)>0 else np.array([])\n",
        "num_out = np.array(num_features)\n",
        "all_feats = np.concatenate([num_out, cat_out])\n",
        "\n",
        "# Coefficients\n",
        "coefs = clf.named_steps[\"model\"].coef_.ravel()\n",
        "feat_importance = pd.DataFrame({\"feature\": all_feats, \"coef\": coefs}).sort_values(\"coef\", ascending=False)\n",
        "feat_importance.head(10)"
      ],
      "metadata": {
        "id": "EJIzzDok3DOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11) Minimal Hyperparameter Tuning (Grid Search)"
      ],
      "metadata": {
        "id": "kgpuxjMx3LTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"model__C\": [0.1, 1.0, 10.0],\n",
        "    \"model__penalty\": [\"l2\"]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(clf, param_grid, cv=3, scoring=\"f1\", n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "best = grid.best_estimator_\n",
        "print(\"Test F1:\", f1_score(y_test, best.predict(X_test)))"
      ],
      "metadata": {
        "id": "4KnKxk5s3JiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12) Save & Load the Trained Pipeline"
      ],
      "metadata": {
        "id": "SpnJ-Gye3OU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(best, \"titanic_logreg_pipeline.joblib\")\n",
        "\n",
        "loaded = joblib.load(\"titanic_logreg_pipeline.joblib\")\n",
        "print(\"Reloaded model test accuracy:\", accuracy_score(y_test, loaded.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "_PoFq7Pt3Pv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13) \"What-If\" Prediction (single row)"
      ],
      "metadata": {
        "id": "gxS7mgQx3RmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a single, realistic passenger row (adjust to the columns you have)\n",
        "one = pd.DataFrame([{\n",
        "    \"pclass\": 2,\n",
        "    \"sex\": \"female\",\n",
        "    \"age\": 28,\n",
        "    \"sibsp\": 0,\n",
        "    \"parch\": 0,\n",
        "    \"fare\": 20.0,\n",
        "    \"embarked\": \"S\"\n",
        "}])\n",
        "\n",
        "print(\"Survival probability:\", loaded.predict_proba(one)[0,1])\n",
        "print(\"Predicted class     :\", int(loaded.predict(one)[0]))"
      ],
      "metadata": {
        "id": "sLny2FAr3Vbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14) EDA"
      ],
      "metadata": {
        "id": "rp3t9RM53Y1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
        "if \"sex\" in X.columns:\n",
        "    (data.groupby(\"sex\")[\"survived\"].mean().sort_values()\n",
        "         .plot(kind=\"barh\", ax=ax[0], title=\"Survival rate by sex\"))\n",
        "if \"pclass\" in X.columns:\n",
        "    (data.groupby(\"pclass\")[\"survived\"].mean().sort_values()\n",
        "         .plot(kind=\"barh\", ax=ax[1], title=\"Survival rate by pclass\"))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9emPZNVY3buG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You now have a clean, end-to-end classifier with:\n",
        "\n",
        "* Train/test split\n",
        "* Robust preprocessing (impute, scale, encode)\n",
        "* Interpretable metrics (Accuracy, P/R/F1, ROC-AUC)\n",
        "* Threshold tuning, CV, light hyperparam search\n",
        "* Save/load + single-row inference"
      ],
      "metadata": {
        "id": "q-X6ji953fV9"
      }
    }
  ]
}