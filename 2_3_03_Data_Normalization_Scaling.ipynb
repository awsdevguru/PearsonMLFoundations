{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awsdevguru/PearsonMLFoundations/blob/main/2_3_03_Data_Normalization_Scaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Normalization & Scaling\n",
        "\n",
        "## 1. Objectives\n",
        "\n",
        "* Why scaling matters\n",
        "* How to apply StandardScaler, MinMaxScaler, RobustScaler\n",
        "* How scaling interacts with outliers\n",
        "* How to visualize and compare scaling\n",
        "* How to integrate scaling into Pipelines & ColumnTransformers\n",
        "\n",
        "## 2. Setup"
      ],
      "metadata": {
        "id": "iq90PBHdj_tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "NPhBoz1qirgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Titanic Dataset"
      ],
      "metadata": {
        "id": "SQoeQNcPitj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"titanic\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_8kBCmIoir8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Select Relevant Columns"
      ],
      "metadata": {
        "id": "3DBSVemziyYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"survived\", \"age\", \"fare\", \"sex\", \"class\"]\n",
        "df = df[cols].copy()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "iO6l3izWixpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Clean Missing Values"
      ],
      "metadata": {
        "id": "j8RimhXfi9BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.dropna(subset=[\"age\", \"fare\", \"sex\", \"class\"])\n",
        "df_clean.isna().sum()"
      ],
      "metadata": {
        "id": "hXUuXhOpi_26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Basic Exploration (Check Scale Differences)"
      ],
      "metadata": {
        "id": "uSLKTDDDjBzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean[[\"age\",\"fare\"]].describe()\n"
      ],
      "metadata": {
        "id": "gYVqHCDZjbqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df_clean[[\"age\",\"fare\"]])\n",
        "plt.title(\"Age vs Fare: Different Scales & Outliers\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WOyrAz2AjbjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Apply Three Scaling Methods"
      ],
      "metadata": {
        "id": "FDTc0N0Ejgcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalers = {\n",
        "    \"StandardScaler\": StandardScaler(),\n",
        "    \"MinMaxScaler\": MinMaxScaler(),\n",
        "    \"RobustScaler\": RobustScaler()\n",
        "}\n",
        "\n",
        "scaled_results = {}\n",
        "\n",
        "for name, scaler in scalers.items():\n",
        "    scaled = scaler.fit_transform(df_clean[[\"age\",\"fare\"]])\n",
        "    scaled_results[name] = pd.DataFrame(\n",
        "        scaled,\n",
        "        columns=[\"age_scaled\", \"fare_scaled\"]\n",
        "    )\n",
        "\n",
        "pd.concat(scaled_results, axis=1).head()"
      ],
      "metadata": {
        "id": "txn_gzJ-jiok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualize the Effects of Scaling"
      ],
      "metadata": {
        "id": "U98IigjvjlNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(18,5))\n",
        "\n",
        "sns.histplot(scaled_results[\"StandardScaler\"][\"fare_scaled\"], kde=True, ax=ax[0])\n",
        "ax[0].set_title(\"StandardScaler — Fare\")\n",
        "\n",
        "sns.histplot(scaled_results[\"MinMaxScaler\"][\"fare_scaled\"], kde=True, ax=ax[1])\n",
        "ax[1].set_title(\"MinMaxScaler — Fare\")\n",
        "\n",
        "sns.histplot(scaled_results[\"RobustScaler\"][\"fare_scaled\"], kde=True, ax=ax[2])\n",
        "ax[2].set_title(\"RobustScaler — Fare\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QeGsURDhjig2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. When to Use Each Scaler\n",
        "\n",
        "* **StandardScaler:** \"Best for linear models (Logistic Reg, SVM).\n",
        "* **MinMaxScaler:** \"Best for neural networks and KNN.\n",
        "* **RobustScaler:** \"Best when data has outliers.\n",
        "\n",
        "## 9. Train/Test Split for Modeling"
      ],
      "metadata": {
        "id": "KiESJHGxjp3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_clean[[\"age\",\"fare\",\"sex\"]]\n",
        "y = df_clean[\"survived\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "E_eMg2zojwPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Build a Pipeline (Scaling + Logistic Regression)"
      ],
      "metadata": {
        "id": "scsMl5Qijyi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "num_cols = [\"age\", \"fare\"]\n",
        "cat_cols = [\"sex\"]\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"scale\", StandardScaler(), num_cols),\n",
        "    (\"encode\", OneHotEncoder(), cat_cols)\n",
        "])"
      ],
      "metadata": {
        "id": "id4BA0Q_j4A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"model\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, preds)\n"
      ],
      "metadata": {
        "id": "wSEfB1Jgj5Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Summary Table of Scaling Methods"
      ],
      "metadata": {
        "id": "CnaNkiUpj7Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = pd.DataFrame({\n",
        "    \"Scaler\": [\"Standard\", \"MinMax\", \"Robust\"],\n",
        "    \"Handles Outliers?\": [\"No\", \"No\", \"Yes\"],\n",
        "    \"Changes Distribution?\": [\"No\", \"No\", \"No\"],\n",
        "    \"Best Use Case\": [\n",
        "        \"Linear/SVM models\",\n",
        "        \"Neural networks / KNN\",\n",
        "        \"Outlier-heavy data\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "summary\n"
      ],
      "metadata": {
        "id": "-LDbBdiej8IM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}